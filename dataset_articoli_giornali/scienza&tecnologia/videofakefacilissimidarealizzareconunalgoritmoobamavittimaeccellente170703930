
OBAMA, seduto nello studio ovale, è come un pupazzo nelle mani di un ventriloquo. Non è una critica politica ma una metafora della sua presenza digitale 'rapita' da un software che gli può far dire di tutto. Il video sembra autentico, la voce, molto ben riconoscibile, è proprio la sua. E quelle parole le ha dette davvero. Ma non nelle circostanze in cui lo stiamo vedendo. Sembra complicato, in realtà è molto semplice: i ricercatori dell'Università di Washington hanno insegnato alle macchine come manipolare il volto dell'ex presidente americano e farlo muovere, parlare, e pronunciare un suo discorso o un'intervista rilasciata altrove, anche molto tempo prima. Il tutto partendo da un semplice file audio. È una specie di lipsync o playback. Ma fatto davvero bene.

·La conversione intelligente
Finora era un effetto ottenuto filmando a lungo persone in uno studio per tracciare i movimenti del volto e associarli ai suoni, in base a come vengono articolati dalle labbra, dalla mandibola e dai muscoli facciali. L'algoritmo messo a punto dal team di Supasorn Suwajanakorn insegna alla macchina a fare la stessa cosa da sola, analizzando i video disponibili online. Ecco spiegato perché la loro 'vittima' è Barack Obama. Perché è facile, solo sul canale Youtube della Casa Bianca ci sono ore e ore di video in alta definizione nei quali la testa occupa una porzione sufficiente dell'inquadratura oltre a centinaia di interviste, videochat e discorsi. Così è possibile anche ascoltare Obama ripetere nello studio della Casa Bianca parole che disse in un'intervista più di un quarto di secolo fa. Con la stessa voce di allora. Proprio come con il pupazzo di un ventriloquo, il programma muove solo la bocca riproducendo i movimenti campionati che ha imparato osservando 17 ore di filmati dello stesso Obama. L'effetto è di un realismo stupefacente, difficile anche chiamarlo “fake”.
Obama 'doppia' se stesso. Fa tutto l'algoritmo: il video fake sembra vero












 
	         




·Le applicazioni: dal gaming alle videochat
Quello che somiglia a uno scherzo, e che può sfociare nella falsificazione, anche grave, di documenti video, è in realtà una ricerca con applicazioni nella vita di tutti i giorni, nel gaming, nel cinema e nei settori in cui il video è predominante, come l'animazione. Ma nella visione degli ideatori può essere utilizzato nelle conversazioni video (Skype, Hangout o Messenger per esempio), quando la banda non è sufficiente: il simulatore riproduce l'immagine realistica del nostro interlocutore, già campionata in precedenza, che dice quello che sentiamo. In modo che la comunicazione avvenga solamente via audio eliminando i problemi di una connessione lenta.

·Effetto perturbante
Uno degli scopi scientifici è quello di risolvere il problema del cosiddetto effetto “Uncanny valley” (zona o valle perturbante). Prende il nome dalla forma del grafico che registra la nostra sensazione di familiarità ed empatia di fronte alla replica di una figura umana. Sensazione che aumenta mano a mano che le sembianze dell'umanoide diventano realistiche. Studi risalenti a quasi 50 anni fa indicavano che oltre una certa soglia di realismo, però, l'atteggiamento si inverte, precipitando in una sensazione di inquietudine e repulsione. Insomma, più il cyborg ci somiglia, più le imperfezioni anche piccole, diventano fastidiose. Una soglia che poi però riprende a salire di nuovo creando la valle nella curva del grafico.

·Il pericolo “fake”. 
Un 'gioco' perfetto per diffondere fake news, sempre più difficili da smascherare, si potrebbe pensare. Ma gli autori dello studio, finanziato anche da Samsung, Google, Facebook e Intel hanno messo seri paletti. Il sistema infatti funziona anche al contrario, come “debunker”. Gli scienziati dell'Università di Seattle hanno infatti scritto anche un algoritmo inverso che analizza un video e capisce se è un falso. Il team della Washington University ha deciso dunque di non 'esagerare': “Non puoi semplicemente prendere la voce di qualcuno e trasformarlo in un video di Obama – spiega Steve Seitz, coautore dell'articolo – abbiamo deciso intenzionalmente di non imboccare questa strada: mettere le parole di altre persone nella bocca di qualcuno. Prendiamo solamente parole vere che qualcuno ha detto e le trasformiamo in un video realistico di quella stessa persona”. Ma in un'epoca in cui anche la sintesi vocale ha fatto passi da gigante, consentendo di far dire a chiunque qualunque cosa campionando anche solo pochi secondi della voce, l'incrocio di queste tecnologie apre praterie sconfinate, e inesplorate, di opportunità e di rischi.






