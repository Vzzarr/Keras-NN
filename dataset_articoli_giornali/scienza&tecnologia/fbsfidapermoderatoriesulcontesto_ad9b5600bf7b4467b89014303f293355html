ROMA - Oltre all'enorme quantità di post pubblicati e segnalati ogni giorno su Facebook, la vera sfida per i moderatori in carne e ossa incaricati di decidere cosa cancellare dalla piattaforma che ha un miliardo di utilizzatori al giorno è quella di "capire il contesto" di quel che gli utenti condividono. Lo afferma la responsabile globale per le policy di Facebook, Monica Bickert, in un lungo post di chiarimenti dopo il polverone sollevato dal Guardian che ha svelato le linee guida segrete del social per la moderazione di argomenti sensibili."Voglio spiegare come e dove tracciamo la linea", scrive, sottolineando che Facebook cerca di essere il più "obiettivo possibile", ma può capitare "a volte di fare la scelta sbagliata". Per i moderatori "è difficile giudicare l'intento che si cela dietro un post o il rischio implicito in un altro", scrive. La sfida è sul contesto. "Qualcuno pubblica un video cruento di un attacco terroristico". Porterà "all'emulazione della violenza o alla sua condanna?", chiede. È quanto accaduto con l'attacco chimico in Siria oggetto di un video diventato virale che mostrava anche bambini agonizzanti: "Le immagini erano scioccanti", ma "hanno anche sollevato indignazione internazionale e riacceso i riflettori sulla Siria".Quanto alla segretezza delle linee guida, precisa, "non vogliamo incoraggiare le persone a trovare modi per aggirarle", ma i "nostri standard" su cosa è ammesso o meno su Facebook sono a disposizione di tutti. E "cambiano nel tempo". E poi ci sono casi "non facili", la "zona grigia" della moderazione. "Arte e pornografia non sempre sono facilmente distinguibili, ma abbiamo rilevato che le immagini di nudità generate digitalmente sono più probabilmente pornografia" e "la nostra policy riflette questo". I moderatori sono "addestrati con esempi estremi", aggiunge. "C'è una grande differenza tra espressioni generiche di rabbia e appelli alla violenza su specifici individui, ecco perché permettiamo le prime ma non i secondi".